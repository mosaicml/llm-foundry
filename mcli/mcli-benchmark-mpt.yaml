name: deepspeed-inference
compute:
  gpus: 8  # Number of GPUs to use

  ## These configurations are optional
  # cluster: TODO # Name of the cluster to use for this run
  # gpu_type: a100_80gb # Type of GPU to use. We use a100_80gb in our experiments

image: mosaicml/llm-foundry:2.2.0_cu121_flash2-latest

integrations:
- integration_type: git_repo
  git_repo: mosaicml/llm-foundry
  git_branch: v0.5.0
  # git_commit: # OR use your commit hash
  pip_install: ".[gpu-flash2]"

command: |
  cd llm-foundry/scripts/inference/benchmarking

  python benchmark.py yamls/1b.yaml
