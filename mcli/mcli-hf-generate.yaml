integrations:
- integration_type: git_repo
  git_repo: mosaicml/llm-foundry
  git_branch: v0.4.0
  # git_commit: # OR use your commit hash
  pip_install: -e .[gpu]
  ssh_clone: false # Should be true if using a private repo

command: |
  cd llm-foundry/scripts/inference

  # s3 commands
  pip install awscli
  aws s3 cp --recursive s3://bucket/folder/hf/ local_hf_folder

  # oci commands
  # pip install oci-cli
  # oci os object bulk-download \
  # -bn bucket --region bucket_region \
  # --prefix folder/hf/ --dest-dir ./
  # # oci downloads the full prefix path, this extracts the innermost folder
  # # into local_hf_folder
  # mv folder/hf/ local_hf_folder

  python hf_generate.py \
    --name_or_path local_hf_folder \
    --temperature 1.0 \
    --top_p 0.95 \
    --top_k 50 \
    --seed 1 \
    --max_new_tokens 256 \
    --prompts \
      "The answer to life, the universe, and happiness is" \
      "MosaicML is an ML training efficiency startup that is known for" \
      "Here's a quick recipe for baking chocolate chip cookies: Start by" \
      "The best 5 cities to visit in Europe are"

image: mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04
name: hf-generate

compute:
  gpus: 8  # Number of GPUs to use

  ## These configurations are optional
  # cluster: TODO # Name of the cluster to use for this run
  # gpu_type: a100_80gb # Type of GPU to use. We use a100_80gb in our experiments
