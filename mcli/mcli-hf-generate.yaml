integrations:
- integration_type: git_repo
  git_repo: mosaicml/llm-foundry
  # git_branch: # use your branch
  # git_commit: # OR use your commit hash
  pip_install: -e .[gpu]
  ssh_clone: false # Should be true if using a private repo

command: |
  cd llm-foundry/llmfoundry/inference

  # s3 commands
  pip install awscli
  aws s3 cp --recursive s3://bucket/folder/hf/ local_hf_folder

  # oci commands
  # pip install oci-cli
  # oci os object bulk-download \
  # -bn bucket --region bucket_region \
  # --prefix folder/hf/ --dest-dir ./
  # # oci downloads the full prefix path, this extracts the innermost folder
  # # into local_hf_folder
  # mv folder/hf/ local_hf_folder

  python hf_generate.py \
    --name_or_path local_hf_folder \
    --temperature 1.0 \
    --top_p 0.95 \
    --top_k 50 \
    --seed 1 \
    --max_new_tokens 256 \
    --prompts \
      "The answer to life, the universe, and happiness is" \
      "MosaicML is an ML training efficiency startup that is known for" \
      "Here's a quick recipe for baking chocolate chip cookies: Start by" \
      "The best 5 cities to visit in Europe are"

image: mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04
optimization_level: 0

# Mosaic Cloud will use run_name (with a unique suffix) to populate the env var $RUN_NAME
run_name: hf-generate

gpu_num: 8
cluster: r0z0 # replace with your cluster here!
