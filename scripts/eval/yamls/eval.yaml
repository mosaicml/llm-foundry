eos_token_id: 0 
tokenizer_name: tiktoken
max_seq_len: 2048
global_seed: 17
run_name: tiktoken
models:
-
  model_name: mpt_causal_lm
  tokenizer:
    name: tiktoken
    kwargs:
      model_name: gpt-4
  load_path: /tmp/model/tessa/uniform2/uniform-dup-sd-1116/ep0-ba24796.pt
  model:
    
    name: mpt_causal_lm
    init_device: meta
    d_model: 2560
    n_heads: 32
    n_layers: 32
    expansion_ratio: 4
    max_seq_len: ${max_seq_len}
    vocab_size: 100352
    tokenizer_name: ${tokenizer_name}
    #loss_fn: torch_crossentropy # Necessary for cuda 12 image
    attn_config:
      attn_impl: triton
      alibi: true
      clip_qkv: 6
      attn_uses_sequence_id: true
      attn_pdrop: 0

    norm_type: low_precision_layernorm
    no_bias: true

    emb_pdrop: 0
    resid_pdrop: 0

    init_config:
      init_nonlinearity: relu
      name: kaiming_normal_

    
device_eval_batch_size: 4
dist_timeout: 60000
fsdp_config:
  sharding_strategy: FULL_SHARD
  mixed_precision: PURE
  activation_checkpointing: false
  activation_checkpointing_reentrant: false
  activation_cpu_offload: false
  limit_all_gathers: true
  verbose: false
  state_dict_type: full
  use_orig_params: false
eval_gauntlet: 'eval/yamls/eval_gauntlet.yaml'
icl_tasks: eval/yamls/tasks.yaml


precision: amp_bf16
seed: 1
